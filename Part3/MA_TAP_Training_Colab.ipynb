{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c9828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0. V√âRIFICATION GPU ET INSTALLATION\n",
    "# ============================================================\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"GPU disponibles:\", tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "# Installation des d√©pendances\n",
    "!pip install mlflow -q\n",
    "print(\"\\n‚úì Setup termin√©!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ae4fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. IMPORTS ET CONFIGURATION\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Cr√©er dossier outputs\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "os.makedirs('figures', exist_ok=True)\n",
    "\n",
    "print(\"‚úì Configuration termin√©e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7789eceb",
   "metadata": {},
   "source": [
    "## 2. Architecture MA-TAP (Innovation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa1f27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. CELLULE MA-TAP (INNOVATION PRINCIPALE)\n",
    "# ============================================================\n",
    "\n",
    "class MATAPCell(layers.Layer):\n",
    "    \"\"\"\n",
    "    Memory-Augmented Time-Aware Path Cell.\n",
    "    \n",
    "    Hybride GRU + M√©moire √âpisodique + Attention pour combattre le Latent Drift.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, memory_size=10, num_heads=4, dropout_rate=0.1, **kwargs):\n",
    "        super(MATAPCell, self).__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.memory_size = memory_size\n",
    "        self.num_heads = num_heads\n",
    "        self.dropout_rate = dropout_rate\n",
    "        \n",
    "        # Composants\n",
    "        self.input_proj = layers.Dense(latent_dim, name=\"input_projection\")\n",
    "        self.gru = layers.GRUCell(latent_dim, name=\"gru_dynamics\")\n",
    "        self.attention = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, \n",
    "            key_dim=latent_dim // num_heads,\n",
    "            value_dim=latent_dim // num_heads,\n",
    "            dropout=dropout_rate,\n",
    "            name=\"retrospective_attention\"\n",
    "        )\n",
    "        self.layer_norm_attn = layers.LayerNormalization()\n",
    "        self.layer_norm_out = layers.LayerNormalization()\n",
    "        self.context_proj = layers.Dense(latent_dim, activation='tanh')\n",
    "        self.gate_dense = layers.Dense(latent_dim, activation='sigmoid')\n",
    "        self.memory_write_proj = layers.Dense(latent_dim)\n",
    "        \n",
    "        self.state_size = [latent_dim, memory_size * latent_dim]\n",
    "        self.output_size = latent_dim\n",
    "\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "        if dtype is None:\n",
    "            dtype = tf.float32\n",
    "        init_h = tf.zeros((batch_size, self.latent_dim), dtype=dtype)\n",
    "        init_memory = tf.zeros((batch_size, self.memory_size * self.latent_dim), dtype=dtype)\n",
    "        return [init_h, init_memory]\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        h_prev, memory_flat = states\n",
    "        batch_size = tf.shape(inputs)[0]\n",
    "        \n",
    "        z_t = self.input_proj(inputs)\n",
    "        memory = tf.reshape(memory_flat, (batch_size, self.memory_size, self.latent_dim))\n",
    "        \n",
    "        # Dynamique locale (GRU)\n",
    "        gru_out, [h_candidate] = self.gru(z_t, [h_prev], training=training)\n",
    "        \n",
    "        # Attention r√©trospective\n",
    "        query = tf.expand_dims(gru_out, axis=1)\n",
    "        context = self.attention(query=query, value=memory, key=memory, training=training)\n",
    "        context = tf.squeeze(context, axis=1)\n",
    "        context = self.layer_norm_attn(context)\n",
    "        context_proj = self.context_proj(context)\n",
    "        \n",
    "        # Fusion adaptative\n",
    "        gate_input = tf.concat([gru_out, context_proj], axis=-1)\n",
    "        alpha = self.gate_dense(gate_input)\n",
    "        h_corrected = (1.0 - alpha) * gru_out + alpha * context_proj\n",
    "        h_corrected = self.layer_norm_out(h_corrected)\n",
    "        \n",
    "        # Mise √† jour m√©moire FIFO\n",
    "        new_entry = self.memory_write_proj(z_t)\n",
    "        new_entry = tf.expand_dims(new_entry, axis=1)\n",
    "        new_memory = tf.concat([memory[:, 1:, :], new_entry], axis=1)\n",
    "        new_memory_flat = tf.reshape(new_memory, (batch_size, self.memory_size * self.latent_dim))\n",
    "        \n",
    "        return h_corrected, [h_corrected, new_memory_flat]\n",
    "\n",
    "\n",
    "class VanillaGRUCell(layers.Layer):\n",
    "    \"\"\"Cellule GRU Baseline (sans m√©moire) pour ablation.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim, **kwargs):\n",
    "        super(VanillaGRUCell, self).__init__(**kwargs)\n",
    "        self.latent_dim = latent_dim\n",
    "        self.state_size = [latent_dim]\n",
    "        self.output_size = latent_dim\n",
    "        self._input_proj = None\n",
    "        self._gru = None\n",
    "        self._layer_norm = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        input_dim = input_shape[-1]\n",
    "        self._input_proj = layers.Dense(self.latent_dim, name=\"baseline_input_proj\")\n",
    "        self._input_proj.build((None, input_dim))\n",
    "        self._gru = layers.GRUCell(self.latent_dim, name=\"baseline_gru\")\n",
    "        self._gru.build((None, self.latent_dim))\n",
    "        self._layer_norm = layers.LayerNormalization(name=\"baseline_ln\")\n",
    "        self._layer_norm.build((None, self.latent_dim))\n",
    "        super().build(input_shape)\n",
    "\n",
    "    def get_initial_state(self, inputs=None, batch_size=None, dtype=None):\n",
    "        if batch_size is None:\n",
    "            batch_size = tf.shape(inputs)[0]\n",
    "        if dtype is None:\n",
    "            dtype = tf.float32\n",
    "        return [tf.zeros((batch_size, self.latent_dim), dtype=dtype)]\n",
    "\n",
    "    def call(self, inputs, states, training=None):\n",
    "        h_prev = states[0]\n",
    "        z_t = self._input_proj(inputs)\n",
    "        gru_out, [h_new] = self._gru(z_t, [h_prev], training=training)\n",
    "        h_new = self._layer_norm(h_new)\n",
    "        return h_new, [h_new]\n",
    "\n",
    "print(\"‚úì Cellules MA-TAP et Baseline d√©finies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13132eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. ENCODEUR/D√âCODEUR SPATIAUX (AM√âLIOR√âS)\n",
    "# ============================================================\n",
    "\n",
    "class SpatialEncoder(keras.Model):\n",
    "    \"\"\"Frame (64x64x1) -> Vecteur Latent - Architecture am√©lior√©e\"\"\"\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(SpatialEncoder, self).__init__()\n",
    "        # Plus de filtres pour meilleure capacit√©\n",
    "        self.conv1 = layers.Conv2D(64, 4, strides=2, padding=\"same\")  # 32->64\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.conv2 = layers.Conv2D(128, 4, strides=2, padding=\"same\")  # 64->128\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.conv3 = layers.Conv2D(256, 4, strides=2, padding=\"same\")  # 128->256\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.conv4 = layers.Conv2D(256, 3, strides=1, padding=\"same\")  # Couche suppl√©mentaire\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")  # 256->512\n",
    "        self.dropout = layers.Dropout(0.3)  # Plus de dropout\n",
    "        self.fc_out = layers.Dense(latent_dim)\n",
    "\n",
    "    def call(self, x, training=False):\n",
    "        x = tf.nn.leaky_relu(self.bn1(self.conv1(x), training=training), 0.2)\n",
    "        x = tf.nn.leaky_relu(self.bn2(self.conv2(x), training=training), 0.2)\n",
    "        x = tf.nn.leaky_relu(self.bn3(self.conv3(x), training=training), 0.2)\n",
    "        x = tf.nn.leaky_relu(self.bn4(self.conv4(x), training=training), 0.2)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x, training=training)\n",
    "        return self.fc_out(x)\n",
    "\n",
    "\n",
    "class SpatialDecoder(keras.Model):\n",
    "    \"\"\"Vecteur Latent -> Frame (64x64x1) - Architecture am√©lior√©e\"\"\"\n",
    "    def __init__(self, latent_dim=128):\n",
    "        super(SpatialDecoder, self).__init__()\n",
    "        self.fc1 = layers.Dense(512, activation=\"relu\")  # 256->512\n",
    "        self.fc2 = layers.Dense(8 * 8 * 256, activation=\"relu\")  # Plus de canaux\n",
    "        self.reshape = layers.Reshape((8, 8, 256))\n",
    "        self.deconv1 = layers.Conv2DTranspose(256, 4, strides=2, padding=\"same\")\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.deconv2 = layers.Conv2DTranspose(128, 4, strides=2, padding=\"same\")\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.deconv3 = layers.Conv2DTranspose(64, 4, strides=2, padding=\"same\")\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        # Couche de raffinement finale\n",
    "        self.refine = layers.Conv2D(32, 3, padding=\"same\")\n",
    "        self.bn4 = layers.BatchNormalization()\n",
    "        self.output_conv = layers.Conv2D(1, 3, padding=\"same\", activation=\"sigmoid\")\n",
    "\n",
    "    def call(self, z, training=False):\n",
    "        x = self.fc1(z)\n",
    "        x = self.fc2(x)\n",
    "        x = self.reshape(x)\n",
    "        x = tf.nn.relu(self.bn1(self.deconv1(x), training=training))\n",
    "        x = tf.nn.relu(self.bn2(self.deconv2(x), training=training))\n",
    "        x = tf.nn.relu(self.bn3(self.deconv3(x), training=training))\n",
    "        x = tf.nn.relu(self.bn4(self.refine(x), training=training))\n",
    "        return self.output_conv(x)\n",
    "\n",
    "print(\"‚úì Encodeur/D√©codeur AM√âLIOR√âS d√©finis\")\n",
    "print(\"  - Encoder: 64->128->256->256 filtres, Leaky ReLU\")\n",
    "print(\"  - Decoder: 256->128->64->32 filtres + refinement layer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bc9ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 4. MOD√àLES COMPLETS (MA-TAP + BASELINE)\n",
    "# ============================================================\n",
    "\n",
    "class MATAPModel(keras.Model):\n",
    "    \"\"\"Mod√®le MA-TAP complet avec m√©moire augment√©e.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=64, memory_size=10, num_heads=4, dropout_rate=0.1):\n",
    "        super(MATAPModel, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        self.memory_size = memory_size\n",
    "        \n",
    "        self.encoder = SpatialEncoder(latent_dim)\n",
    "        self.decoder = SpatialDecoder(latent_dim)\n",
    "        self.matap_cell = MATAPCell(latent_dim, memory_size, num_heads, dropout_rate)\n",
    "        self.rnn = layers.RNN(self.matap_cell, return_sequences=True, return_state=True)\n",
    "        self.predictor = keras.Sequential([\n",
    "            layers.Dense(latent_dim * 2, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(latent_dim)\n",
    "        ])\n",
    "    \n",
    "    def encode_sequence(self, frames, training=False):\n",
    "        B, T = tf.shape(frames)[0], tf.shape(frames)[1]\n",
    "        flat = tf.reshape(frames, (B * T, 64, 64, 1))\n",
    "        z_flat = self.encoder(flat, training=training)\n",
    "        return tf.reshape(z_flat, (B, T, self.latent_dim))\n",
    "    \n",
    "    def decode_sequence(self, z_seq, training=False):\n",
    "        B, T = tf.shape(z_seq)[0], tf.shape(z_seq)[1]\n",
    "        z_flat = tf.reshape(z_seq, (B * T, self.latent_dim))\n",
    "        frames_flat = self.decoder(z_flat, training=training)\n",
    "        return tf.reshape(frames_flat, (B, T, 64, 64, 1))\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        B = tf.shape(inputs)[0]\n",
    "        z_seq = self.encode_sequence(inputs, training=training)\n",
    "        initial_states = self.matap_cell.get_initial_state(batch_size=B)\n",
    "        h_seq, final_h, final_memory = self.rnn(z_seq, initial_state=initial_states, training=training)\n",
    "        z_pred = self.predictor(h_seq)\n",
    "        reconstructed = self.decode_sequence(z_pred, training=training)\n",
    "        return reconstructed, z_seq, z_pred, [final_h, final_memory]\n",
    "\n",
    "\n",
    "class BaselineTAPModel(keras.Model):\n",
    "    \"\"\"Mod√®le Baseline GRU (sans m√©moire) pour ablation.\"\"\"\n",
    "    \n",
    "    def __init__(self, latent_dim=64, dropout_rate=0.1):\n",
    "        super(BaselineTAPModel, self).__init__()\n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = SpatialEncoder(latent_dim)\n",
    "        self.decoder = SpatialDecoder(latent_dim)\n",
    "        self.gru_cell = VanillaGRUCell(latent_dim)\n",
    "        self.rnn = layers.RNN(self.gru_cell, return_sequences=True, return_state=True)\n",
    "        self.predictor = keras.Sequential([\n",
    "            layers.Dense(latent_dim * 2, activation='relu'),\n",
    "            layers.Dropout(dropout_rate),\n",
    "            layers.Dense(latent_dim)\n",
    "        ])\n",
    "    \n",
    "    def encode_sequence(self, frames, training=False):\n",
    "        B, T = tf.shape(frames)[0], tf.shape(frames)[1]\n",
    "        flat = tf.reshape(frames, (B * T, 64, 64, 1))\n",
    "        z_flat = self.encoder(flat, training=training)\n",
    "        return tf.reshape(z_flat, (B, T, self.latent_dim))\n",
    "    \n",
    "    def decode_sequence(self, z_seq, training=False):\n",
    "        B, T = tf.shape(z_seq)[0], tf.shape(z_seq)[1]\n",
    "        z_flat = tf.reshape(z_seq, (B * T, self.latent_dim))\n",
    "        frames_flat = self.decoder(z_flat, training=training)\n",
    "        return tf.reshape(frames_flat, (B, T, 64, 64, 1))\n",
    "    \n",
    "    def call(self, inputs, training=False):\n",
    "        B = tf.shape(inputs)[0]\n",
    "        z_seq = self.encode_sequence(inputs, training=training)\n",
    "        initial_states = self.gru_cell.get_initial_state(batch_size=B)\n",
    "        h_seq, final_h = self.rnn(z_seq, initial_state=initial_states, training=training)\n",
    "        z_pred = self.predictor(h_seq)\n",
    "        reconstructed = self.decode_sequence(z_pred, training=training)\n",
    "        return reconstructed, z_seq, z_pred, [final_h]\n",
    "\n",
    "print(\"‚úì Mod√®les MA-TAP et Baseline d√©finis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. G√âN√âRATEUR MOVING MNIST\n",
    "# ============================================================\n",
    "\n",
    "class MovingMNISTGenerator:\n",
    "    \"\"\"G√©n√®re des s√©quences Moving MNIST.\"\"\"\n",
    "    \n",
    "    def __init__(self, image_size=64, digit_size=28, num_digits=2, seq_length=20):\n",
    "        self.image_size = image_size\n",
    "        self.digit_size = digit_size\n",
    "        self.num_digits = num_digits\n",
    "        self.seq_length = seq_length\n",
    "        \n",
    "        # Charger MNIST\n",
    "        (x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "        self.mnist_train = x_train.astype(np.float32) / 255.0\n",
    "        self.mnist_test = x_test.astype(np.float32) / 255.0\n",
    "        print(f\"[MovingMNIST] Loaded {len(self.mnist_train)} train, {len(self.mnist_test)} test digits\")\n",
    "    \n",
    "    def _get_random_digit(self, use_test=False):\n",
    "        data = self.mnist_test if use_test else self.mnist_train\n",
    "        return data[np.random.randint(len(data))]\n",
    "    \n",
    "    def _generate_trajectory(self, seq_length):\n",
    "        x = np.random.randint(0, self.image_size - self.digit_size)\n",
    "        y = np.random.randint(0, self.image_size - self.digit_size)\n",
    "        speed = np.random.uniform(2, 5)\n",
    "        angle = np.random.uniform(0, 2 * np.pi)\n",
    "        vx, vy = speed * np.cos(angle), speed * np.sin(angle)\n",
    "        \n",
    "        positions = []\n",
    "        for _ in range(seq_length):\n",
    "            positions.append((int(x), int(y)))\n",
    "            x, y = x + vx, y + vy\n",
    "            if x < 0 or x > self.image_size - self.digit_size:\n",
    "                vx = -vx\n",
    "                x = np.clip(x, 0, self.image_size - self.digit_size)\n",
    "            if y < 0 or y > self.image_size - self.digit_size:\n",
    "                vy = -vy\n",
    "                y = np.clip(y, 0, self.image_size - self.digit_size)\n",
    "        return positions\n",
    "    \n",
    "    def generate_sequence(self, use_test=False):\n",
    "        seq = np.zeros((self.seq_length, self.image_size, self.image_size, 1), dtype=np.float32)\n",
    "        for _ in range(self.num_digits):\n",
    "            digit = self._get_random_digit(use_test)\n",
    "            traj = self._generate_trajectory(self.seq_length)\n",
    "            for t, (x, y) in enumerate(traj):\n",
    "                x_end = min(x + self.digit_size, self.image_size)\n",
    "                y_end = min(y + self.digit_size, self.image_size)\n",
    "                seq[t, y:y_end, x:x_end, 0] = np.clip(\n",
    "                    seq[t, y:y_end, x:x_end, 0] + digit[:y_end-y, :x_end-x], 0, 1\n",
    "                )\n",
    "        return seq\n",
    "    \n",
    "    def generate_batch(self, batch_size, use_test=False):\n",
    "        batch = np.zeros((batch_size, self.seq_length, self.image_size, self.image_size, 1), dtype=np.float32)\n",
    "        for i in range(batch_size):\n",
    "            batch[i] = self.generate_sequence(use_test)\n",
    "        return batch\n",
    "\n",
    "# Initialiser le g√©n√©rateur\n",
    "data_gen = MovingMNISTGenerator(seq_length=20, num_digits=2)\n",
    "print(\"‚úì G√©n√©rateur Moving MNIST pr√™t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381a40e",
   "metadata": {},
   "source": [
    "## 6. Entra√Ænement (Version AM√âLIOR√âE)\n",
    "\n",
    "### Changements par rapport √† la version pr√©c√©dente :\n",
    "\n",
    "| Param√®tre | Avant | Apr√®s | Raison |\n",
    "|-----------|-------|-------|--------|\n",
    "| `latent_dim` | 64 | **128** | Plus de capacit√© pour repr√©senter les digits |\n",
    "| `epochs` | 50 | **150** | Convergence compl√®te |\n",
    "| `learning_rate` | 1e-3 | **5e-4** | Gradients plus stables |\n",
    "| `batch_size` | 32 | **16** | Meilleure g√©n√©ralisation |\n",
    "| `latent_loss_weight` | 0.1 | **0.01** | Focus sur reconstruction |\n",
    "| `encoder filters` | 32-64-128 | **64-128-256-256** | Plus de capacit√© |\n",
    "| `LR schedule` | Constant | **Cosine Decay** | Meilleure convergence |\n",
    "| `Loss` | BCE | **MSE + 0.5*BCE** | Meilleurs gradients pour pixels |\n",
    "\n",
    "‚ö†Ô∏è **Temps estim√© sur T4 GPU : ~45-60 minutes** (vs ~25 min avant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d77cc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6. CONFIGURATION D'ENTRA√éNEMENT (AM√âLIOR√âE)\n",
    "# ============================================================\n",
    "\n",
    "CONFIG = {\n",
    "    # Architecture - AUGMENT√âE pour meilleure capacit√©\n",
    "    'latent_dim': 128,          # 64 -> 128 pour plus de capacit√©\n",
    "    'memory_size': 10,\n",
    "    'num_heads': 4,\n",
    "    'seq_length': 20,\n",
    "    \n",
    "    # Training - AJUST√â pour meilleure convergence\n",
    "    'batch_size': 16,           # 32 -> 16 pour gradients plus stables\n",
    "    'epochs': 150,              # 50 -> 150 pour vraiment converger\n",
    "    'learning_rate': 5e-4,      # 1e-3 -> 5e-4 plus doux\n",
    "    \n",
    "    # Data\n",
    "    'num_train_samples': 3000,\n",
    "    'num_val_samples': 500,\n",
    "    \n",
    "    # Loss weighting\n",
    "    'latent_loss_weight': 0.01,  # 0.1 -> 0.01 focus sur reconstruction\n",
    "}\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURATION AM√âLIOR√âE POUR RECONSTRUCTION\")\n",
    "print(\"=\"*60)\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47a251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 7. FONCTIONS D'ENTRA√éNEMENT (AM√âLIOR√âES)\n",
    "# ============================================================\n",
    "\n",
    "def create_train_step(model, optimizer, latent_weight=0.01):\n",
    "    \"\"\"Cr√©e une fonction d'entra√Ænement sp√©cifique au mod√®le.\"\"\"\n",
    "    @tf.function\n",
    "    def train_step(batch):\n",
    "        with tf.GradientTape() as tape:\n",
    "            reconstructed, z_true, z_pred, _ = model(batch, training=True)\n",
    "            \n",
    "            # Loss reconstruction PRINCIPALE (MSE pour meilleurs gradients)\n",
    "            loss_mse = tf.reduce_mean(tf.square(batch - reconstructed))\n",
    "            \n",
    "            # Loss BCE additionnelle\n",
    "            loss_bce = tf.reduce_mean(keras.losses.binary_crossentropy(batch, reconstructed))\n",
    "            \n",
    "            # Loss reconstruction combin√©e\n",
    "            loss_rec = loss_mse + 0.5 * loss_bce\n",
    "            \n",
    "            # Loss pr√©diction latente (r√©duite)\n",
    "            loss_latent = tf.reduce_mean(tf.square(z_true[:, 1:] - z_pred[:, :-1]))\n",
    "            \n",
    "            total_loss = loss_rec + latent_weight * loss_latent\n",
    "        \n",
    "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "        gradients, _ = tf.clip_by_global_norm(gradients, 1.0)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        \n",
    "        # SSIM\n",
    "        B, T = tf.shape(batch)[0], tf.shape(batch)[1]\n",
    "        y_true = tf.reshape(batch, (B * T, 64, 64, 1))\n",
    "        y_pred = tf.reshape(reconstructed, (B * T, 64, 64, 1))\n",
    "        ssim = tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "        \n",
    "        return total_loss, ssim, loss_mse\n",
    "    return train_step\n",
    "\n",
    "def create_val_step(model, latent_weight=0.01):\n",
    "    \"\"\"Cr√©e une fonction de validation sp√©cifique au mod√®le.\"\"\"\n",
    "    @tf.function\n",
    "    def val_step(batch):\n",
    "        reconstructed, z_true, z_pred, _ = model(batch, training=False)\n",
    "        \n",
    "        loss_mse = tf.reduce_mean(tf.square(batch - reconstructed))\n",
    "        loss_bce = tf.reduce_mean(keras.losses.binary_crossentropy(batch, reconstructed))\n",
    "        loss_rec = loss_mse + 0.5 * loss_bce\n",
    "        loss_latent = tf.reduce_mean(tf.square(z_true[:, 1:] - z_pred[:, :-1]))\n",
    "        total_loss = loss_rec + latent_weight * loss_latent\n",
    "        \n",
    "        B, T = tf.shape(batch)[0], tf.shape(batch)[1]\n",
    "        y_true = tf.reshape(batch, (B * T, 64, 64, 1))\n",
    "        y_pred = tf.reshape(reconstructed, (B * T, 64, 64, 1))\n",
    "        ssim = tf.reduce_mean(tf.image.ssim(y_true, y_pred, max_val=1.0))\n",
    "        \n",
    "        return total_loss, ssim\n",
    "    return val_step\n",
    "\n",
    "def train_model(model, model_name, epochs=150):\n",
    "    \"\"\"Entra√Æne un mod√®le avec learning rate scheduler.\"\"\"\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Entra√Ænement {model_name} (AM√âLIOR√â)\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Optimizer avec learning rate decay\n",
    "    lr_schedule = keras.optimizers.schedules.CosineDecay(\n",
    "        initial_learning_rate=CONFIG['learning_rate'],\n",
    "        decay_steps=epochs * (CONFIG['num_train_samples'] // CONFIG['batch_size']),\n",
    "        alpha=0.1  # Decay to 10% of initial LR\n",
    "    )\n",
    "    optimizer = keras.optimizers.Adam(learning_rate=lr_schedule)\n",
    "    \n",
    "    # Cr√©er les fonctions sp√©cifiques\n",
    "    train_step = create_train_step(model, optimizer, CONFIG['latent_loss_weight'])\n",
    "    val_step = create_val_step(model, CONFIG['latent_loss_weight'])\n",
    "    \n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_ssim': [], 'val_ssim': []}\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    patience = 20  # Early stopping patience\n",
    "    \n",
    "    # G√©n√©rer les donn√©es\n",
    "    print(\"G√©n√©ration des donn√©es...\")\n",
    "    train_data = data_gen.generate_batch(CONFIG['num_train_samples'])\n",
    "    val_data = data_gen.generate_batch(CONFIG['num_val_samples'], use_test=True)\n",
    "    \n",
    "    num_batches = CONFIG['num_train_samples'] // CONFIG['batch_size']\n",
    "    num_val_batches = CONFIG['num_val_samples'] // CONFIG['batch_size']\n",
    "    \n",
    "    print(f\"D√©marrage ({epochs} epochs, {num_batches} batches/epoch, LR cosine decay)...\\n\")\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle\n",
    "        indices = np.random.permutation(CONFIG['num_train_samples'])\n",
    "        train_data_shuffled = train_data[indices]\n",
    "        \n",
    "        # Training\n",
    "        train_losses, train_ssims = [], []\n",
    "        for i in range(num_batches):\n",
    "            batch = train_data_shuffled[i*CONFIG['batch_size']:(i+1)*CONFIG['batch_size']]\n",
    "            loss, ssim, mse = train_step(batch)\n",
    "            train_losses.append(loss.numpy())\n",
    "            train_ssims.append(ssim.numpy())\n",
    "        \n",
    "        # Validation\n",
    "        val_losses, val_ssims = [], []\n",
    "        for i in range(num_val_batches):\n",
    "            batch = val_data[i*CONFIG['batch_size']:(i+1)*CONFIG['batch_size']]\n",
    "            loss, ssim = val_step(batch)\n",
    "            val_losses.append(loss.numpy())\n",
    "            val_ssims.append(ssim.numpy())\n",
    "        \n",
    "        # Moyennes\n",
    "        train_loss = np.mean(train_losses)\n",
    "        val_loss = np.mean(val_losses)\n",
    "        train_ssim = np.mean(train_ssims)\n",
    "        val_ssim = np.mean(val_ssims)\n",
    "        \n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['train_ssim'].append(train_ssim)\n",
    "        history['val_ssim'].append(val_ssim)\n",
    "        \n",
    "        # Affichage (tous les 10 epochs ou d√©but/fin)\n",
    "        if epoch % 10 == 0 or epoch == epochs - 1 or epoch < 5:\n",
    "            print(f\"Epoch {epoch+1:3d}/{epochs} | \"\n",
    "                  f\"Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | \"\n",
    "                  f\"Train SSIM: {train_ssim:.4f} | Val SSIM: {val_ssim:.4f}\")\n",
    "        \n",
    "        # Sauvegarde meilleur mod√®le\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            model.save_weights(f'outputs/{model_name}_best.weights.h5')\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        \n",
    "        # Early stopping (d√©sactiv√© pour training complet)\n",
    "        # if patience_counter >= patience:\n",
    "        #     print(f\"\\n‚ö†Ô∏è Early stopping at epoch {epoch+1}\")\n",
    "        #     break\n",
    "    \n",
    "    # Sauvegarde finale\n",
    "    model.save_weights(f'outputs/{model_name}_final.weights.h5')\n",
    "    print(f\"\\n‚úì {model_name} termin√©! Best Val Loss: {best_val_loss:.4f}\")\n",
    "    print(f\"  Final Val SSIM: {val_ssim:.4f}\")\n",
    "    \n",
    "    return history\n",
    "\n",
    "print(\"‚úì Fonctions d'entra√Ænement AM√âLIOR√âES d√©finies\")\n",
    "print(\"  - Loss: MSE + 0.5*BCE (meilleur pour pixels)\")\n",
    "print(\"  - Learning Rate: Cosine Decay\")\n",
    "print(\"  - Latent loss weight r√©duit: 0.01\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e2e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 8. ENTRA√éNEMENT MA-TAP (avec latent_dim=128)\n",
    "# ============================================================\n",
    "\n",
    "# Cr√©er le mod√®le MA-TAP avec capacit√© augment√©e\n",
    "matap_model = MATAPModel(\n",
    "    latent_dim=CONFIG['latent_dim'],  # 128 maintenant\n",
    "    memory_size=CONFIG['memory_size'],\n",
    "    num_heads=CONFIG['num_heads']\n",
    ")\n",
    "\n",
    "# Build\n",
    "dummy = tf.zeros((1, CONFIG['seq_length'], 64, 64, 1))\n",
    "_ = matap_model(dummy)\n",
    "num_params = sum([tf.reduce_prod(v.shape).numpy() for v in matap_model.trainable_variables])\n",
    "print(f\"MA-TAP param√®tres: {num_params:,}\")\n",
    "print(f\"  (latent_dim={CONFIG['latent_dim']}, memory_size={CONFIG['memory_size']})\")\n",
    "\n",
    "# Entra√Æner avec plus d'epochs\n",
    "history_matap = train_model(matap_model, 'matap', epochs=CONFIG['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f7397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 9. ENTRA√éNEMENT BASELINE (avec latent_dim=128)\n",
    "# ============================================================\n",
    "\n",
    "# Cr√©er le mod√®le Baseline avec capacit√© augment√©e\n",
    "baseline_model = BaselineTAPModel(latent_dim=CONFIG['latent_dim'])  # 128 maintenant\n",
    "\n",
    "# Build\n",
    "dummy_baseline = tf.zeros((2, CONFIG['seq_length'], 64, 64, 1))\n",
    "_ = baseline_model(dummy_baseline, training=True)\n",
    "\n",
    "# Warmup pour initialiser les variables\n",
    "print(\"Warmup du mod√®le Baseline...\")\n",
    "warmup_optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "with tf.GradientTape() as tape:\n",
    "    out, z_true, z_pred, _ = baseline_model(dummy_baseline, training=True)\n",
    "    warmup_loss = tf.reduce_mean(out)\n",
    "grads = tape.gradient(warmup_loss, baseline_model.trainable_variables)\n",
    "warmup_optimizer.apply_gradients(zip(grads, baseline_model.trainable_variables))\n",
    "\n",
    "num_params = sum([tf.reduce_prod(v.shape).numpy() for v in baseline_model.trainable_variables])\n",
    "print(f\"Baseline param√®tres: {num_params:,}\")\n",
    "print(f\"  (latent_dim={CONFIG['latent_dim']})\")\n",
    "\n",
    "# Recr√©er le mod√®le pour repartir de z√©ro apr√®s warmup\n",
    "baseline_model = BaselineTAPModel(latent_dim=CONFIG['latent_dim'])\n",
    "dummy_baseline = tf.zeros((2, CONFIG['seq_length'], 64, 64, 1))\n",
    "_ = baseline_model(dummy_baseline, training=True)\n",
    "\n",
    "# Entra√Æner avec plus d'epochs\n",
    "history_baseline = train_model(baseline_model, 'baseline', epochs=CONFIG['epochs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "686b2451",
   "metadata": {},
   "source": [
    "## 10. Visualisations et R√©sultats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f157e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 10. G√âN√âRATION DES FIGURES\n",
    "# ============================================================\n",
    "\n",
    "# Figure 1: Courbes d'apprentissage\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Loss\n",
    "axes[0].plot(history_matap['train_loss'], 'b-', label='MA-TAP Train', linewidth=2)\n",
    "axes[0].plot(history_matap['val_loss'], 'b--', label='MA-TAP Val', linewidth=2)\n",
    "axes[0].plot(history_baseline['train_loss'], 'r-', label='Baseline Train', linewidth=2)\n",
    "axes[0].plot(history_baseline['val_loss'], 'r--', label='Baseline Val', linewidth=2)\n",
    "axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "axes[0].set_ylabel('Loss', fontsize=12)\n",
    "axes[0].set_title('Training & Validation Loss', fontsize=14)\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# SSIM\n",
    "axes[1].plot(history_matap['train_ssim'], 'b-', label='MA-TAP Train', linewidth=2)\n",
    "axes[1].plot(history_matap['val_ssim'], 'b--', label='MA-TAP Val', linewidth=2)\n",
    "axes[1].plot(history_baseline['train_ssim'], 'r-', label='Baseline Train', linewidth=2)\n",
    "axes[1].plot(history_baseline['val_ssim'], 'r--', label='Baseline Val', linewidth=2)\n",
    "axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "axes[1].set_ylabel('SSIM', fontsize=12)\n",
    "axes[1].set_title('Structural Similarity Index', fontsize=14)\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/training_curves.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Figure sauvegard√©e: figures/training_curves.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f15254c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 11. √âVALUATION SSIM PAR TIMESTEP\n",
    "# ============================================================\n",
    "\n",
    "def compute_ssim_per_timestep(model, test_data):\n",
    "    \"\"\"Calcule SSIM pour chaque timestep.\"\"\"\n",
    "    reconstructed, _, _, _ = model(test_data, training=False)\n",
    "    T = test_data.shape[1]\n",
    "    ssim_per_t = []\n",
    "    for t in range(T):\n",
    "        ssim = tf.image.ssim(test_data[:, t], reconstructed[:, t], max_val=1.0)\n",
    "        ssim_per_t.append(tf.reduce_mean(ssim).numpy())\n",
    "    return ssim_per_t\n",
    "\n",
    "# G√©n√©rer donn√©es de test\n",
    "test_data = data_gen.generate_batch(100, use_test=True)\n",
    "\n",
    "# Calculer SSIM\n",
    "ssim_matap = compute_ssim_per_timestep(matap_model, test_data)\n",
    "ssim_baseline = compute_ssim_per_timestep(baseline_model, test_data)\n",
    "\n",
    "# Figure 2: SSIM temporel\n",
    "plt.figure(figsize=(10, 6))\n",
    "timesteps = range(len(ssim_matap))\n",
    "plt.plot(timesteps, ssim_matap, 'b-o', linewidth=2, markersize=6, label='MA-TAP (Ours)')\n",
    "plt.plot(timesteps, ssim_baseline, 'r--s', linewidth=2, markersize=6, label='Baseline (GRU)')\n",
    "plt.xlabel('Timestep', fontsize=12)\n",
    "plt.ylabel('SSIM', fontsize=12)\n",
    "plt.title('Temporal Coherence: SSIM over Time', fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.ylim([0, 1])\n",
    "plt.savefig('figures/ssim_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Figure sauvegard√©e: figures/ssim_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e963b147",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 12. VISUALISATION DES RECONSTRUCTIONS\n",
    "# ============================================================\n",
    "\n",
    "# Prendre une s√©quence de test\n",
    "sample = test_data[0:1]  # (1, T, 64, 64, 1)\n",
    "rec_matap, _, _, _ = matap_model(sample, training=False)\n",
    "rec_baseline, _, _, _ = baseline_model(sample, training=False)\n",
    "\n",
    "# Afficher\n",
    "T = sample.shape[1]\n",
    "fig, axes = plt.subplots(3, min(T, 10), figsize=(20, 6))\n",
    "\n",
    "for t in range(min(T, 10)):\n",
    "    axes[0, t].imshow(sample[0, t, :, :, 0], cmap='gray', vmin=0, vmax=1)\n",
    "    axes[0, t].axis('off')\n",
    "    axes[0, t].set_title(f't={t}', fontsize=9)\n",
    "    \n",
    "    axes[1, t].imshow(rec_matap[0, t, :, :, 0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "    axes[1, t].axis('off')\n",
    "    \n",
    "    axes[2, t].imshow(rec_baseline[0, t, :, :, 0].numpy(), cmap='gray', vmin=0, vmax=1)\n",
    "    axes[2, t].axis('off')\n",
    "\n",
    "axes[0, 0].set_ylabel('Ground Truth', fontsize=11)\n",
    "axes[1, 0].set_ylabel('MA-TAP', fontsize=11)\n",
    "axes[2, 0].set_ylabel('Baseline', fontsize=11)\n",
    "\n",
    "plt.suptitle('Reconstruction Comparison', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.savefig('figures/reconstruction_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"‚úì Figure sauvegard√©e: figures/reconstruction_comparison.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f0b43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 13. R√âSUM√â DES R√âSULTATS\n",
    "# ============================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"R√âSULTATS FINAUX\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\nüìä MA-TAP:\")\n",
    "print(f\"   Final Train Loss: {history_matap['train_loss'][-1]:.4f}\")\n",
    "print(f\"   Final Val Loss:   {history_matap['val_loss'][-1]:.4f}\")\n",
    "print(f\"   Final Train SSIM: {history_matap['train_ssim'][-1]:.4f}\")\n",
    "print(f\"   Final Val SSIM:   {history_matap['val_ssim'][-1]:.4f}\")\n",
    "print(f\"   Best Val Loss:    {min(history_matap['val_loss']):.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Baseline:\")\n",
    "print(f\"   Final Train Loss: {history_baseline['train_loss'][-1]:.4f}\")\n",
    "print(f\"   Final Val Loss:   {history_baseline['val_loss'][-1]:.4f}\")\n",
    "print(f\"   Final Train SSIM: {history_baseline['train_ssim'][-1]:.4f}\")\n",
    "print(f\"   Final Val SSIM:   {history_baseline['val_ssim'][-1]:.4f}\")\n",
    "print(f\"   Best Val Loss:    {min(history_baseline['val_loss']):.4f}\")\n",
    "\n",
    "# Am√©lioration\n",
    "ssim_improvement = (history_matap['val_ssim'][-1] - history_baseline['val_ssim'][-1]) / history_baseline['val_ssim'][-1] * 100\n",
    "print(f\"\\nüéØ Am√©lioration SSIM MA-TAP vs Baseline: {ssim_improvement:+.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c86c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 14. T√âL√âCHARGEMENT DES R√âSULTATS\n",
    "# ============================================================\n",
    "\n",
    "# Cr√©er un zip avec tous les r√©sultats\n",
    "import shutil\n",
    "\n",
    "# Sauvegarder les historiques\n",
    "np.savez('outputs/training_history.npz', \n",
    "         matap_train_loss=history_matap['train_loss'],\n",
    "         matap_val_loss=history_matap['val_loss'],\n",
    "         matap_train_ssim=history_matap['train_ssim'],\n",
    "         matap_val_ssim=history_matap['val_ssim'],\n",
    "         baseline_train_loss=history_baseline['train_loss'],\n",
    "         baseline_val_loss=history_baseline['val_loss'],\n",
    "         baseline_train_ssim=history_baseline['train_ssim'],\n",
    "         baseline_val_ssim=history_baseline['val_ssim'])\n",
    "\n",
    "# Cr√©er le zip\n",
    "shutil.make_archive('MA_TAP_Results', 'zip', '.', 'outputs')\n",
    "shutil.make_archive('MA_TAP_Figures', 'zip', '.', 'figures')\n",
    "\n",
    "print(\"‚úì Fichiers cr√©√©s:\")\n",
    "print(\"  - MA_TAP_Results.zip (poids des mod√®les + historiques)\")\n",
    "print(\"  - MA_TAP_Figures.zip (toutes les figures)\")\n",
    "print(\"\\nüì• T√©l√©chargez ces fichiers depuis le panneau de gauche!\")\n",
    "\n",
    "# Pour Google Colab - t√©l√©chargement automatique\n",
    "try:\n",
    "    from google.colab import files\n",
    "    files.download('MA_TAP_Results.zip')\n",
    "    files.download('MA_TAP_Figures.zip')\n",
    "except:\n",
    "    print(\"(T√©l√©chargement manuel depuis le panneau de fichiers)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d01eaab",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ‚úÖ Entra√Ænement Termin√©!\n",
    "\n",
    "### Fichiers g√©n√©r√©s:\n",
    "- `outputs/matap_best.weights.h5` - Meilleurs poids MA-TAP\n",
    "- `outputs/baseline_best.weights.h5` - Meilleurs poids Baseline\n",
    "- `outputs/training_history.npz` - Historiques d'entra√Ænement\n",
    "- `figures/training_curves.png` - Courbes d'apprentissage\n",
    "- `figures/ssim_comparison.png` - Comparaison SSIM temporel\n",
    "- `figures/reconstruction_comparison.png` - Visualisation reconstructions\n",
    "\n",
    "### Pour utiliser ces r√©sultats dans ton projet local:\n",
    "1. T√©l√©charge les fichiers `.zip`\n",
    "2. Copie les `.weights.h5` dans `Part3/experiments/outputs/`\n",
    "3. Copie les `.png` dans `Part3/experiments/outputs/`\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
