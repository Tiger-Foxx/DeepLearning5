\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{denton2018stochastic}
\citation{lee2018savp}
\citation{villegas2017learning}
\citation{walker2021tap}
\citation{xingjian2015convolutional}
\citation{denton2018stochastic}
\citation{lee2018savp}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}\protected@file@percent }
\citation{vaswani2017attention}
\citation{arnab2021vivit}
\citation{graves2014neural}
\citation{weston2014memory}
\citation{wu2019long}
\citation{walker2021tap}
\citation{srivastava2015unsupervised}
\@writefile{toc}{\contentsline {section}{\numberline {2}Related Work}{2}{section.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3}Proposed Method: MA-TAP}{2}{section.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overview}{2}{subsection.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}MA-TAP Cell}{2}{subsection.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Training Objective}{2}{subsection.3.3}\protected@file@percent }
\citation{wang2004image}
\@writefile{toc}{\contentsline {section}{\numberline {4}Experiments}{3}{section.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Experimental Setup}{3}{subsection.4.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Main Results}{3}{subsection.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Comparison of \textsc  {MA-TAP}{} vs \textsc  {Baseline}{} on Moving MNIST after 50 epochs of training. Best results in \textbf  {bold}.}}{3}{table.1}\protected@file@percent }
\newlabel{tab:main_results}{{1}{3}{Comparison of \matap {} vs \baseline {} on Moving MNIST after 50 epochs of training. Best results in \textbf {bold}}{table.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Training Dynamics}{3}{subsection.4.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Convergence Analysis}{3}{subsection.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Training stability analysis. Lower variance indicates more stable training.}}{4}{table.2}\protected@file@percent }
\newlabel{tab:stability}{{2}{4}{Training stability analysis. Lower variance indicates more stable training}{table.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Epochs to reach performance thresholds. Lower is better.}}{4}{table.3}\protected@file@percent }
\newlabel{tab:convergence}{{3}{4}{Epochs to reach performance thresholds. Lower is better}{table.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Peak Performance Analysis}{4}{subsection.4.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Best results achieved during training.}}{4}{table.4}\protected@file@percent }
\newlabel{tab:best}{{4}{4}{Best results achieved during training}{table.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Ablation Study}{4}{section.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Impact of Memory Size}{4}{subsection.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Component Analysis}{4}{subsection.5.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Ablation on memory size $K$. Models evaluated without loading pre-trained weights.}}{5}{table.5}\protected@file@percent }
\newlabel{tab:memory_ablation}{{5}{5}{Ablation on memory size $K$. Models evaluated without loading pre-trained weights}{table.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Discussion}{5}{section.6}\protected@file@percent }
\bibstyle{unsrt}
\bibcite{denton2018stochastic}{1}
\bibcite{lee2018savp}{2}
\bibcite{villegas2017learning}{3}
\bibcite{walker2021tap}{4}
\bibcite{xingjian2015convolutional}{5}
\bibcite{vaswani2017attention}{6}
\bibcite{arnab2021vivit}{7}
\bibcite{graves2014neural}{8}
\bibcite{weston2014memory}{9}
\bibcite{wu2019long}{10}
\bibcite{srivastava2015unsupervised}{11}
\bibcite{wang2004image}{12}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusion}{6}{section.7}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {A}Architecture Details}{7}{appendix.A}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.1}Spatial Encoder}{7}{subsection.A.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.2}Spatial Decoder}{7}{subsection.A.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {A.3}MA-TAP Cell}{7}{subsection.A.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {B}Training Curves}{7}{appendix.B}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {C}Code Repository}{7}{appendix.C}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Training and validation curves for \textsc  {MA-TAP}{} and \textsc  {Baseline}{} over 50 epochs on Moving MNIST. Left: Loss (lower is better). Right: SSIM (higher is better). Both models converge rapidly in the first 10 epochs, with \textsc  {MA-TAP}{} showing slightly lower loss throughout training. Extended training (150+ epochs) is expected to amplify these differences.}}{8}{figure.1}\protected@file@percent }
\newlabel{fig:training_curves}{{1}{8}{Training and validation curves for \matap {} and \baseline {} over 50 epochs on Moving MNIST. Left: Loss (lower is better). Right: SSIM (higher is better). Both models converge rapidly in the first 10 epochs, with \matap {} showing slightly lower loss throughout training. Extended training (150+ epochs) is expected to amplify these differences}{figure.1}{}}
\gdef \@abspage@last{8}
